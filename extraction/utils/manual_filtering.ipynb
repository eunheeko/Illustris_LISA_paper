{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelkatz/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import h5py\n",
    "\n",
    "h=0.704"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script allows the user to manually filter for some ID changes that were missed by the algorithm. This number usually numbers under 100. The idea is to find clear instances where the first time an ID is seen is for a large black hole. This clearly means a seed merged into the large black hole and the seed ID was chosen. \n",
    "\n",
    "1) The user can look at the large black holes whose IDs appear randomly\n",
    "\n",
    "2) Check the last snapshot for black holes with an almost identical mass\n",
    "\n",
    "3) Add them to the list\n",
    "\n",
    "4) Make the necessary changes for these IDs\n",
    "\n",
    "This method is not perfect. But close examination shows it will solve a majority of the remaining issues. If you want to skip this execute the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ONLY EXECUTE THIS IF YOU DO NOT WANT TO DO THE MANUAL SEARCH ####\n",
    "with open('manual_search_not_done.txt', 'r') as fp:\n",
    "    fp.write('not doing manual search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, load information from the new details catalog. This step takes the longest due to the sorting operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('bhs_details_new.hdf5', 'r') as f:\n",
    "    pid_det_old = f['id'][:] \n",
    "    pid_det = f['id_new'][:] \n",
    "    time_det = f['time'][:]\n",
    "    mass_det = f['mass'][:]*1e10/h\n",
    "\n",
    "details =  np.core.records.fromarrays([f['id'][:], f['mass'][:]*1e10/0.704, f['time'][:]], names='id,mass,time')\n",
    "\n",
    "sort_inds = np.argsort(details, order=('time', 'mass'))\n",
    "\n",
    "details = details[sort_inds]\n",
    "\n",
    "#sort old ids in same order as the new ideas\n",
    "pid_det_old = pid_det_old[sort_inds]\n",
    "\n",
    "#do the same for index into the dataset\n",
    "old_indices = np.arange(len(pid_det_old))[sort_inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort information for the all bhs dataset and sort the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelkatz/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('bhs_all_new.hdf5', 'r') as f:\n",
    "    pid = f['ParticleIDs_new'][:] \n",
    "    pid_old = f['ParticleIDs'][:] \n",
    "    snap = f['Snapshot'][:]\n",
    "    mass = f['BH_Mass'][:]\n",
    "\n",
    "checker = [(pid[i], snap[i], mass[i], pid_old[i]) for i in range(len(pid))]\n",
    "\n",
    "checker = np.asarray(checker, dtype=[('id', np.dtype(np.uint64)), ('snap', np.dtype(float)), ('mass', np.dtype(float)), ('id_old', np.dtype(float))])\n",
    "\n",
    "checker = np.sort(checker, order=['id', 'snap'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to find all the black holes who appeared at a higher mass than the seeds for its first appearance. We also need to find the last time a bh appeared and its mass. Therefore, we can find bhs that disappeared right before a snapshot where a new black hole appeared with almost exactly the same mass as the one that disappeared. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the first instance an id appears in the all dataset\n",
    "pid_uni, uni_ind = np.unique(checker['id'], return_index=True)\n",
    "\n",
    "#this is the mass when it first appears\n",
    "init_mass = checker['mass'][uni_ind]\n",
    "\n",
    "#need to check indices where the first time seeing a black hole, it has a mass greater than 10^6\n",
    "inds_check = np.where(init_mass>1e6)[0]\n",
    "\n",
    "#snaps that require you to check black holes in\n",
    "snaps_init_to_check = checker['snap'][uni_ind][inds_check]\n",
    "\n",
    "#new ids that need to be checked\n",
    "ids_to_check = checker['id'][uni_ind][inds_check]\n",
    "\n",
    "#masses of those to check\n",
    "mass_to_check = checker['mass'][uni_ind][inds_check]\n",
    "\n",
    "#old ids \n",
    "old_ids_to_check = checker['id_old'][uni_ind][inds_check]\n",
    "\n",
    "#refers the ids because now you want to see the last time a black hole appears\n",
    "pid_uni_backward, last_ind = np.unique(checker['id'][::-1], return_index=True)\n",
    "\n",
    "#mass at bh's final appearance\n",
    "final_mass = checker['mass'][::-1][last_ind]\n",
    "snaps_final = checker['snap'][::-1][last_ind]\n",
    "\n",
    "print('We need to check %i black holes.'%len(ids_to_check))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we search for all the black holes we found in the earlier steps. We put them in an array that will let us observe if these misplaced black holes can be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "finished=0\n",
    "print(len(ids_to_check))\n",
    "\n",
    "#we have the information for the black hole that is left over. Now we search\n",
    "#for the second black hole that lost its id in the merger that fits criteria to \n",
    "#simplify search.\n",
    "for id1, mass, snap, id1_old in np.array([ids_to_check, mass_to_check, snaps_init_to_check, old_ids_to_check]).T:\n",
    "    \n",
    "    #find where the details id is the id of black hole left over and take its time and mass values\n",
    "    inds = np.where(details['id'] == id1)[0]\n",
    "    time_sort = details['time'][inds]\n",
    "    mass_sort = details['mass'][inds]\n",
    "\n",
    "    #find where the log10 of the mass values takes the largest jump (upping mass orders of magnitude)\n",
    "    ind_switch  = np.where(np.diff(np.log10(details['mass'][inds])) == np.diff(np.log10(details['mass'][inds])).max())[0][0]\n",
    "\n",
    "    #ind_out_1 is when they switch\n",
    "    ind_out_1 = inds[ind_switch]\n",
    "    \n",
    "    #ind_out_2 is first index after switch\n",
    "    ind_out_2 = inds[ind_switch+1]\n",
    "\n",
    "    time_switch = details['time'][ind_out_1]\n",
    "\n",
    "    time_out_2 = details['time'][ind_out_2]\n",
    "\n",
    "    mass_switch = details['mass'][ind_out_1]\n",
    "\n",
    "    #looking for other blackholes that have the same specific time value of the switch\n",
    "    inds_at_switch = np.where(details['time'] == time_switch)[0]\n",
    "    \n",
    "    #look at the first black hole found above\n",
    "    ind_search = inds_at_switch[-1] + 1\n",
    "\n",
    "    inds_of_interest = []\n",
    "    \n",
    "    #walk through black holes for those that fit these criterion and append them to ids_of_interest to look at later\n",
    "    while details['time'][ind_search]<details['time'][ind_out_2]:\n",
    "        if details['mass'][ind_search]>details['mass'][ind_out_2]/2 and details['mass'][ind_search]<details['mass'][ind_out_2]:\n",
    "            inds_of_interest.append(ind_search)\n",
    "        ind_search += 1\n",
    "    \n",
    "    #look at the old ids of interes\n",
    "    ids_of_interest = pid_det_old[inds_of_interest]\n",
    "\n",
    "    for i, id2 in enumerate(ids_of_interest):\n",
    "        #find everywhere this id of interest appears in old details ids\n",
    "        inds_find = np.where((pid_det_old == id2))[0]\n",
    "\n",
    "        if len(inds_find) != 0:\n",
    "            total mass of both black holes before switch\n",
    "            total_mass = details['mass'][inds_find][-1] + details['mass'][ind_out_1]\n",
    "            #if this pair of black holes have the same time switch coordinate and \n",
    "            #the mass of the remaing black hole is greater than or equal to\n",
    "            #the combination of the constituent black holes. Also the total mass \n",
    "            #is greater than half of the mass of black hole that loses its id (this constrains output).\n",
    "            if details['time'][inds_find][-2] == time_switch and total_mass <= details['mass'][ind_out_2] and total_mass > details['mass'][ind_out_2]/2:\n",
    "                ind_in = inds_find[-1]\n",
    "                \n",
    "                #append black holes that fit this criterion\n",
    "                out.append([finished, old_indices[ind_out_1], old_indices[ind_in], old_indices[ind_out_2], pid_det_old[ind_out_1], pid_det_old[ind_in], pid_det_old[ind_out_2], details['mass'][ind_out_1], details['mass'][ind_in], details['mass'][ind_out_2],details['time'][ind_out_1], details['time'][ind_in], details['time'][ind_out_2]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we output this array we found, look through it and locate mergers that we missed so we can correct their ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 [0.142123578125 33.742188 33.891904]\n",
      "1 0 [0.142123578125 17.498154 33.891904]\n",
      "2 1 [0.142058234375 1076.441856 1080.282624]\n",
      "3 2 [0.142045453125 4394.971648 4395.127808]\n",
      "4 3 [0.154813921875 215.23152 216.9716]\n",
      "5 4 [0.142326703125 2632.229888 2633.338112]\n",
      "6 5 [0.1445838125 667.774208 668.646336]\n",
      "7 6 [0.142045453125 2896.420352 2897.045504]\n",
      "8 7 [0.142045453125 4430.951424 4433.86368]\n",
      "9 8 [0.142051140625 1905.653504 1905.965824]\n",
      "10 8 [0.142051140625 1567.471616 1905.965824]\n",
      "11 9 [0.143342328125 283.428992 283.669024]\n",
      "12 10 [0.14320028125 304.981536 305.375008]\n",
      "13 11 [0.143379265625 6653.906432 6654.247424]\n",
      "14 12 [0.142345171875 37.43608 37.578976]\n",
      "15 12 [0.142345171875 28.287358 37.578976]\n",
      "16 12 [0.142345171875 24.935512 37.578976]\n",
      "17 13 [0.142046875 1287.933312 1288.683136]\n",
      "18 14 [0.1420525625 5657.017344 5657.201664]\n",
      "19 15 [0.142613640625 2957.641984 2958.068224]\n",
      "20 16 [0.142045453125 276.880704 311.573856]\n",
      "21 16 [0.142045453125 311.421888 311.573856]\n",
      "22 16 [0.142045453125 202.572448 311.573856]\n",
      "23 17 [0.143428984375 1511.420416 1511.67616]\n",
      "24 18 [0.142048296875 6158.892544 6161.88928]\n",
      "25 19 [0.14209090625 1193.169024 1193.512704]\n",
      "26 21 [0.142423296875 2046.71872 2046.87488]\n",
      "27 21 [0.142423296875 1634.261248 2046.87488]\n",
      "28 22 [0.14239915625 50.0902 50.26676]\n",
      "29 23 [0.142045453125 7573.09696 7574.218752]\n",
      "30 24 [0.142045453125 1509.85792 1592.244352]\n",
      "31 24 [0.142045453125 862.070976 1592.244352]\n",
      "32 24 [0.142045453125 1590.610688 1592.244352]\n",
      "33 26 [0.142045453125 85.767472 85.909944]\n",
      "34 27 [0.142045453125 1681.008512 1681.1648]\n",
      "35 28 [0.142045453125 4066.065408 4066.420736]\n",
      "36 29 [0.142045453125 4015.582208 5092.145152]\n",
      "37 30 [0.142046875 5228.01152 5228.153344]\n",
      "38 31 [0.142051140625 395.375008 395.572448]\n",
      "39 32 [0.14204971875 1756.264192 1756.71872]\n",
      "40 33 [0.142045453125 5874.999808 5875.809792]\n",
      "41 34 [0.142045453125 1499.985792 1500.79552]\n",
      "42 34 [0.142045453125 913.122176 1500.79552]\n",
      "43 34 [0.142045453125 1383.347968 1500.79552]\n",
      "44 35 [0.228123578125 6361.563136 6367.414784]\n",
      "45 36 [0.143377828125 1597.443328 1599.488512]\n",
      "46 37 [0.142045453125 1537.428864 1538.835328]\n",
      "47 37 [0.142045453125 1339.019904 1538.835328]\n",
      "48 38 [0.14371165625 1490.95168 1491.349376]\n",
      "49 39 [0.14244034375 1553.153408 1554.360704]\n",
      "50 39 [0.14244034375 997.048384 1554.360704]\n",
      "51 41 [0.142061078125 5920.369664 5920.511488]\n",
      "52 42 [0.142048296875 7.4392755 13.422003]\n",
      "53 43 [0.142045453125 84.36776 132.157952]\n",
      "54 43 [0.142045453125 131.846024 132.157952]\n",
      "55 44 [0.142046875 733.225856 1002.56672]\n",
      "56 44 [0.142046875 1001.684672 1002.56672]\n",
      "57 47 [0.142045453125 5323.152896 5323.579904]\n",
      "58 48 [2.7225285 1918.224384 1920.965888]\n",
      "59 50 [0.142045453125 562.571008 562.715904]\n",
      "60 51 [0.14210653125 3981.73312 3983.622144]\n",
      "61 52 [0.142045453125 1.50029825 2.517358]\n",
      "62 53 [0.142045453125 752.286912 752.433216]\n",
      "63 54 [0.142045453125 2776.321024 2776.463104]\n",
      "64 55 [0.142045453125 2283.082496 2283.224576]\n",
      "65 56 [0.142045453125 10126.889984 10129.09056]\n",
      "66 59 [0.142045453125 5385.2416 5385.383424]\n",
      "67 61 [0.142048296875 322.15344 322.38352]\n",
      "68 62 [0.142045453125 1159.154944 1159.4304]\n",
      "69 67 [0.142045453125 2871.562496 2871.704576]\n",
      "70 74 [0.142045453125 1683.536896 1683.679104]\n",
      "71 76 [0.142045453125 5385.2416 6597.074432]\n",
      "72 81 [0.142045453125 373.606528 374.065344]\n",
      "73 85 [0.142045453125 11195.185152 11195.327488]\n",
      "74 90 [0.142045453125 6607.102464 6607.244288]\n"
     ]
    }
   ],
   "source": [
    "outc = np.asarray(out, dtype=object)\n",
    "for j, out_vals in enumerate(outc):\n",
    "    #here, j is the number of pair we searched, out_vals[0] is the merger number. \n",
    "    #then there is the time (scale) at which this takes place. \n",
    "    #Finally, the mass of the larger black hole that has its id removed and the mass of the black hole\n",
    "    #appears in the next snapshot with a very similar mass. This black hole id belonged to a much smaller \n",
    "    #black hole at the previous snapshot. \n",
    "    #some mergers may have more than one potential pair. This is why we search manually. \n",
    "    print(j, out_vals[0], out_vals[7:10]/1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look through the list above for pairs that do not look like reasonable candidates. For example, if we have:\n",
    "\n",
    "0 0 [0.142123578125 33.742188 33.891904]\n",
    "\n",
    "1 0 [0.142123578125 17.498154 33.891904]\n",
    "\n",
    "These are both for the same merger 0 (this is just the number merger in the mergers we are examining, not the overall index). It is clear the first entry is the black hole we are looking for. The second is not. Therefore we add the index 1 to the bad list below to remove it from the final tally.\n",
    "\n",
    "Another example:\n",
    "\n",
    "41 34 [0.142045453125 1499.985792 1500.79552]\n",
    "\n",
    "42 34 [0.142045453125 913.122176 1500.79552]\n",
    "\n",
    "43 34 [0.142045453125 1383.347968 1500.79552]\n",
    "\n",
    "All for the same merger. For what we are looking for, a seed black hole into a very large black hole, we expect the mass change in the $\\geq10^{10}M_\\odot$ black to be about equal to the seed mass. Therefore, the correct merger in this example is 41. \n",
    "\n",
    "42 is clearly wrong. 43 has too large of a change to be from a seed mass black hole. We add 42 and 43 to the bad list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_list = [1, 15, 16, 20, 22, 27, 30, 31, 42, 43, 47, 50, 53, 55, 10, 36, 52, 61, 71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the bad list\n",
    "out_cleaned = np.delete(outc, , axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[142123.58 33742188.0 33891904.0]\n",
      " [142058.23 1076441900.0 1080282600.0]\n",
      " [142045.45 4394971600.0 4395128000.0]\n",
      " [154813.92 215231520.0 216971600.0]\n",
      " [142326.7 2632230000.0 2633338000.0]\n",
      " [144583.81 667774200.0 668646340.0]\n",
      " [142045.45 2896420400.0 2897045500.0]\n",
      " [142045.45 4430951400.0 4433863700.0]\n",
      " [142051.14 1905653500.0 1905965800.0]\n",
      " [143342.33 283429000.0 283669020.0]\n",
      " [143200.28 304981540.0 305375000.0]\n",
      " [143379.27 6653906400.0 6654247400.0]\n",
      " [142345.17 37436080.0 37578976.0]\n",
      " [142046.88 1287933300.0 1288683100.0]\n",
      " [142052.56 5657017300.0 5657201700.0]\n",
      " [142613.64 2957642000.0 2958068200.0]\n",
      " [142045.45 311421900.0 311573860.0]\n",
      " [143428.98 1511420400.0 1511676200.0]\n",
      " [142048.3 6158892500.0 6161889300.0]\n",
      " [142090.9 1193169000.0 1193512700.0]\n",
      " [142423.3 2046718700.0 2046874900.0]\n",
      " [142399.16 50090200.0 50266760.0]\n",
      " [142045.45 7573097000.0 7574219000.0]\n",
      " [142045.45 1590610700.0 1592244400.0]\n",
      " [142045.45 85767470.0 85909944.0]\n",
      " [142045.45 1681008500.0 1681164800.0]\n",
      " [142045.45 4066065400.0 4066420700.0]\n",
      " [142046.88 5228011500.0 5228153300.0]\n",
      " [142051.14 395375000.0 395572450.0]\n",
      " [142049.72 1756264200.0 1756718700.0]\n",
      " [142045.45 5875000000.0 5875810000.0]\n",
      " [142045.45 1499985800.0 1500795500.0]\n",
      " [228123.58 6361563000.0 6367415000.0]\n",
      " [143377.83 1597443300.0 1599488500.0]\n",
      " [142045.45 1537428900.0 1538835300.0]\n",
      " [143711.66 1490951700.0 1491349400.0]\n",
      " [142440.34 1553153400.0 1554360700.0]\n",
      " [142061.08 5920369700.0 5920511500.0]\n",
      " [142045.45 131846024.0 132157950.0]\n",
      " [142046.88 1001684700.0 1002566700.0]\n",
      " [142045.45 5323153000.0 5323580000.0]\n",
      " [2722528.5 1918224400.0 1920965900.0]\n",
      " [142045.45 562571000.0 562715900.0]\n",
      " [142106.53 3981733000.0 3983622100.0]\n",
      " [142045.45 752286900.0 752433200.0]\n",
      " [142045.45 2776321000.0 2776463000.0]\n",
      " [142045.45 2283082500.0 2283224600.0]\n",
      " [142045.45 10126890000.0 10129091000.0]\n",
      " [142045.45 5385241600.0 5385383400.0]\n",
      " [142048.3 322153440.0 322383520.0]\n",
      " [142045.45 1159155000.0 1159430400.0]\n",
      " [142045.45 2871562500.0 2871704600.0]\n",
      " [142045.45 1683536900.0 1683679100.0]\n",
      " [142045.45 373606530.0 374065340.0]\n",
      " [142045.45 11195185000.0 11195327000.0]\n",
      " [142045.45 6607102500.0 6607244300.0]]\n"
     ]
    }
   ],
   "source": [
    "print(out_cleaned[:, 7:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REMEMBER TO ADD DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './extraction_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(directory + 'fix_list.txt', out_cleaned, fmt = '%i\\t%i\\t%i\\t%i\\t%i\\t%i\\t%i\\t%.18e\\t%.18e\\t%.18e\\t%.18e\\t%.18e\\t%.18e', header = 'search_index\\tind_out_1\\tind_in\\tind_out_2\\tid_out_1\\tid_in\\tid_out2\\tmass_out_1\\tmass_in\\tmass_out_2\\ttime_out_1\\ttime_in\\ttime_out_2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
